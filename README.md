# NLP Bias Analyzer

**DÃ©tection des doubles standards dans la couverture mÃ©diatique de la guerre Ã  Gaza**

Projet de fin d'Ã©tudes - Master 2 HPC  
UniversitÃ© des Sciences et de la Technologie Houari Boumediene (USTHB)

---

## ğŸ“‹ Table des matiÃ¨res

- [Description](#description)
- [FonctionnalitÃ©s](#fonctionnalitÃ©s)
- [Architecture](#architecture)
- [Installation](#installation)
- [Utilisation](#utilisation)
- [Structure du projet](#structure-du-projet)
- [RÃ©sultats attendus](#rÃ©sultats-attendus)
- [Contributeurs](#contributeurs)

---

## ğŸ¯ Description

Ce projet utilise des techniques de **Traitement Automatique du Langage Naturel (NLP)** pour analyser et quantifier les biais dans la couverture mÃ©diatique occidentale de la guerre Ã  Gaza, en la comparant Ã  celle de la guerre en Ukraine.

### Objectifs principaux

- **Analyser les biais lexicaux**: Identifier les diffÃ©rences de vocabulaire utilisÃ© pour dÃ©crire les acteurs des deux conflits
- **Examiner le ton Ã©motionnel**: Comparer l'empathie et l'humanisation dans les descriptions
- **Ã‰tudier le framing sÃ©mantique**: Analyser les cadres interprÃ©tatifs et les associations de mots
- **DÃ©tecter les euphÃ©mismes**: Identifier l'usage sÃ©lectif de termes techniques vs directs

### HypothÃ¨ses de recherche

1. **Biais internes**: Les mÃ©dias occidentaux appliquent des standards diffÃ©rents aux acteurs palestiniens et israÃ©liens
2. **Biais systÃ©miques**: La couverture de Gaza montre moins d'empathie que celle de l'Ukraine

---

## âœ¨ FonctionnalitÃ©s

### ğŸ” Analyses

- **Analyse Lexicale**
  - FrÃ©quences de mots
  - Analyse TF-IDF
  - Cooccurrences et associations
  - N-grams (bigrams, trigrams)
  - DÃ©tection de patterns de biais (termes dÃ©shumanisants vs humanisants)

- **Analyse SÃ©mantique**
  - Concordance (contextes d'utilisation)
  - Champs sÃ©mantiques
  - Associations entre mots
  - Collocations
  - Comparaison des contextes entre conflits

- **Analyse de Sentiment**
  - Analyse multi-modÃ¨les (TextBlob, VADER, Transformers)
  - Sentiment par article et par topic
  - Analyse par mots-cibles
  - Comparaison Ã©motionnelle
  - Ã‰volution temporelle

### ğŸ“Š Visualisations

- Graphiques de frÃ©quences de mots
- RÃ©seaux de cooccurrences
- Cartes de chaleur de contextes
- Distribution du sentiment
- Tableaux de bord comparatifs

### ğŸŒ Interface Web

- Explorateur de corpus
- Tableau de bord d'analyse
- DÃ©tecteur de biais interactif
- Galerie de visualisations
- GÃ©nÃ©ration de rapports PDF

### ğŸ“„ Rapports

- Rapport HTML interactif
- Rapport PDF professionnel
- Export CSV des rÃ©sultats
- Visualisations intÃ©grÃ©es

---

## ğŸ— Architecture

```
nlp_bias_analysis/
â”‚
â”œâ”€â”€ config/
â”‚   â””â”€â”€ config.yaml              # Configuration du projet
â”‚
â”œâ”€â”€ data_collection/
â”‚   â”œâ”€â”€ collectors.py            # Collecteurs d'articles
â”‚   â””â”€â”€ sample_generator.py      # GÃ©nÃ©rateur de corpus d'exemple
â”‚
â”œâ”€â”€ preprocessing/
â”‚   â””â”€â”€ text_processor.py        # Nettoyage et prÃ©traitement
â”‚
â”œâ”€â”€ analysis/
â”‚   â”œâ”€â”€ lexical_analyzer.py      # Analyse lexicale
â”‚   â”œâ”€â”€ semantic_analyzer.py     # Analyse sÃ©mantique
â”‚   â””â”€â”€ sentiment_analyzer.py    # Analyse de sentiment
â”‚
â”œâ”€â”€ visualization/
â”‚   â””â”€â”€ visualizer.py            # GÃ©nÃ©ration de visualisations
â”‚
â”œâ”€â”€ web_interface/
â”‚   â”œâ”€â”€ app.py                   # Application Flask
â”‚   â””â”€â”€ templates/               # Templates HTML
â”‚
â”œâ”€â”€ reports/
â”‚   â””â”€â”€ report_generator.py      # GÃ©nÃ©ration de rapports
â”‚
â”œâ”€â”€ corpus/                      # DonnÃ©es collectÃ©es
â”œâ”€â”€ preprocessed/                # DonnÃ©es prÃ©traitÃ©es
â”œâ”€â”€ analysis_results/            # RÃ©sultats d'analyse
â”œâ”€â”€ visualizations/              # Graphiques et visualisations
â”‚
â”œâ”€â”€ main.py                      # Script principal
â”œâ”€â”€ requirements.txt             # DÃ©pendances Python
â””â”€â”€ README.md                    # Documentation
```

---

## ğŸš€ Installation

### PrÃ©requis

- Python 3.8 ou plus rÃ©cent
- pip (gestionnaire de packages Python)

### Ã‰tapes d'installation

1. **Cloner le projet**
   ```bash
   git clone <url-du-repo>
   cd nlp_bias_analysis
   ```

2. **CrÃ©er un environnement virtuel**
   ```bash
   python -m venv venv
   source venv/bin/activate  # Linux/Mac
   # ou
   venv\Scripts\activate     # Windows
   ```

3. **Installer les dÃ©pendances**
   ```bash
   pip install -r requirements.txt
   ```

4. **TÃ©lÃ©charger les ressources NLTK**
   ```python
   import nltk
   nltk.download('punkt')
   nltk.download('stopwords')
   nltk.download('wordnet')
   nltk.download('averaged_perceptron_tagger')
   ```

5. **Installer spaCy (optionnel)**
   ```bash
   python -m spacy download en_core_web_sm
   ```

6. **Installer WeasyPrint pour les PDFs (optionnel)**
   ```bash
   pip install weasyprint
   ```

---

## ğŸ’» Utilisation

### Pipeline complet

ExÃ©cutez toutes les Ã©tapes du pipeline d'analyse:

```bash
python main.py --full
```

### Ã‰tapes individuelles

```bash
# 1. GÃ©nÃ©rer un corpus d'exemple
python main.py --step generate_sample_corpus

# 2. PrÃ©traiter les donnÃ©es
python main.py --step preprocess

# 3. Analyse lexicale
python main.py --step lexical_analysis

# 4. Analyse sÃ©mantique
python main.py --step semantic_analysis

# 5. Analyse de sentiment
python main.py --step sentiment_analysis

# 6. GÃ©nÃ©rer les visualisations
python main.py --step visualize

# 7. GÃ©nÃ©rer le rapport
python main.py --step generate_report
```

### Interface web

```bash
# Lancer l'interface Flask
python main.py --web
```

Puis ouvrez votre navigateur: `http://127.0.0.1:5000`

### Utilisation avancÃ©e

```bash
# SpÃ©cifier un fichier de configuration personnalisÃ©
python main.py --full --config config/my_config.yaml

# ExÃ©cuter avec des logs dÃ©taillÃ©s
python main.py --full --log-level DEBUG
```

---

## ğŸ“– Structure du projet

### Configuration (`config/`)

- `config.yaml`: ParamÃ¨tres de collecte, analyse et visualisation

### Collecte de donnÃ©es (`data_collection/`)

- **collectors.py**: Collecteurs pour CNN, BBC, New York Times
- **sample_generator.py**: GÃ©nÃ¨re un corpus d'exemple avec des patterns de biais connus

### PrÃ©traitement (`preprocessing/`)

- **text_processor.py**: Nettoyage, tokenisation, lemmatisation

### Analyse (`analysis/`)

- **lexical_analyzer.py**: Analyse des frÃ©quences, TF-IDF, patterns de biais
- **semantic_analyzer.py**: Concordance, champs sÃ©mantiques, associations
- **sentiment_analyzer.py**: Analyse multi-modÃ¨les de sentiment

### Visualisation (`visualization/`)

- **visualizer.py**: GÃ©nÃ©ration de graphiques interactifs et statiques

### Interface web (`web_interface/`)

- **app.py**: Application Flask
- **templates/**: Pages HTML (accueil, corpus, analyse, etc.)

### Rapports (`reports/`)

- **report_generator.py**: GÃ©nÃ©ration de rapports PDF et HTML

---

## ğŸ“Š RÃ©sultats attendus

### Analyse 1: Biais internes

**HypothÃ¨se**: Les mÃ©dias occidentaux appliquent des standards diffÃ©rents aux acteurs palestiniens et israÃ©liens.

**Observations attendues**:
- Les Palestiniens sont dÃ©crits avec des termes dÃ©shumanisants ("militants", "terrorists")
- Les IsraÃ©liens sont dÃ©crits avec empathie ("civilians", "victims")
- Attribution de responsabilitÃ© asymÃ©trique
- Contextualisation diffÃ©renciÃ©e

### Analyse 2: Biais systÃ©miques

**HypothÃ¨se**: La couverture de Gaza montre moins d'empathie que celle de l'Ukraine.

**Observations attendues**:
- Pour l'Ukraine: ton hÃ©roÃ¯que et empathique ("heroic resistance", "fight for freedom")
- Pour Gaza: ton neutre et technique ("conflict", "military operation")
- EuphÃ©misation plus marquÃ©e pour Gaza
- Humanisation limitÃ©e, privilÃ©giant les statistiques aux rÃ©cits personnels

### Visualisations clÃ©s

1. **FrÃ©quences de mots**: Top 50 mots les plus frÃ©quents par conflit
2. **RÃ©seaux de cooccurrences**: Mots associÃ©s Ã  "Palestinians" vs "Ukrainians"
3. **Distribution du sentiment**: Comparaison des tons Ã©motionnels
4. **Cartes de chaleur**: Contextes d'utilisation des mots-clÃ©s
5. **Tableaux de bord**: SynthÃ¨se des biais dÃ©tectÃ©s

---

## ğŸ“ Ã‰valuation

### CritÃ¨res de rÃ©ussite

- **Collecte de donnÃ©es**: 50-100 articles pour Gaza, 30-50 pour l'Ukraine
- **Analyse linguistique**: Patterns pertinents et argumentÃ©s
- **Visualisations**: Graphiques et statistiques obligatoires
- **OriginalitÃ©**: MÃ©thodologie et visualisations innovantes

### Livrables

1. **Rapport PDF** (20 pages max)
   - MÃ©thodologie et rÃ©sultats
   - Visualisations et analyse critique
   - DÃ©claration de contribution

2. **DÃ©pÃ´t GitHub**
   - Corpus organisÃ©
   - Code source complet
   - Scripts de reproductibilitÃ©

3. **Application/DÃ©monstration**
   - Interface utilisateur
   - Visualisations interactives
   - Consultation des corpus

---

## ğŸ‘¥ Contributeurs

Ce projet a Ã©tÃ© dÃ©veloppÃ© dans le cadre du module **Natural Language Processing** du **Master 2 HPC** Ã  l'**USTHB**.

**Instructeur**: Dr. S. KALI ALI (skaliali.usthb@gmail.com)

### Guide de contribution

1. Fork le projet
2. CrÃ©ez une branche pour votre fonctionnalitÃ© (`git checkout -b feature/AmazingFeature`)
3. Commit vos changements (`git commit -m 'Add some AmazingFeature'`)
4. Push vers la branche (`git push origin feature/AmazingFeature`)
5. Ouvrez une Pull Request

---

## ğŸ“„ Licence

Ce projet est destinÃ© Ã  des fins Ã©ducatives dans le cadre du Master 2 HPC Ã  l'USTHB.

---

## ğŸ™ Remerciements

- **Dr. S. KALI ALI** - Instructeur du module NLP
- **USTHB** - UniversitÃ© des Sciences et de la Technologie Houari Boumediene
- **CommunautÃ© open source** - Pour les excellentes bibliothÃ¨ques NLP utilisÃ©es

---

## ğŸ“ Support

Pour toute question ou suggestion, veuillez contacter:

- Email: skaliali.usthb@gmail.com
- Module: Natural Language Processing - Master 2 HPC
- AnnÃ©e universitaire: 2025-2026

---

<div align="center">
    <p><strong>NLP Bias Analyzer</strong></p>
    <p>DÃ©tection des doubles standards dans la couverture mÃ©diatique</p>
    <p><em>Master 2 HPC - USTHB - 2025-2026</em></p>
</div>