"""
Script principal pour le projet NLP Bias Analyzer
Orchestre toutes les √©tapes du pipeline d'analyse
"""

import os
import sys
import argparse
import logging
from datetime import datetime

# Ajouter les r√©pertoires au path
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

# Configuration du logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


class PipelineOrchestrator:
    """Orchestre le pipeline complet d'analyse NLP"""
    
    def __init__(self, config_path="config/config.yaml"):
        self.config_path = config_path
        self.results = {}
    
    def run_step(self, step_name: str, **kwargs):
        """
        Ex√©cute une √©tape sp√©cifique du pipeline
        
        Args:
            step_name: Nom de l'√©tape
            **kwargs: Arguments sp√©cifiques √† l'√©tape
        """
        
        logger.info(f"Ex√©cution de l'√©tape: {step_name}")
        
        if step_name == "generate_sample_corpus":
            return self._generate_sample_corpus()
        
        elif step_name == "preprocess":
            return self._preprocess_corpus(kwargs.get('corpus_path'))
        
        elif step_name == "lexical_analysis":
            return self._run_lexical_analysis(kwargs.get('corpus_path'))
        
        elif step_name == "semantic_analysis":
            return self._run_semantic_analysis(kwargs.get('corpus_path'))
        
        elif step_name == "sentiment_analysis":
            return self._run_sentiment_analysis(kwargs.get('corpus_path'))
        
        elif step_name == "visualize":
            return self._generate_visualizations()
        
        elif step_name == "generate_report":
            return self._generate_report()
        
        elif step_name == "run_web_interface":
            return self._run_web_interface()
        
        else:
            raise ValueError(f"√âape inconnue: {step_name}")
    
    def _generate_sample_corpus(self):
        """G√©n√®re un corpus d'exemple"""
        
        try:
            from data_collection.sample_generator import SampleCorpusGenerator
            
            generator = SampleCorpusGenerator()
            corpus = generator.generate_corpus()
            
            logger.info(f"Corpus d'exemple g√©n√©r√©: {len(corpus)} articles")
            return True
        
        except Exception as e:
            logger.error(f"Erreur lors de la g√©n√©ration du corpus: {e}")
            return False
    
    def _preprocess_corpus(self, corpus_path=None):
        """Pr√©traite le corpus"""
        
        try:
            from preprocessing.text_processor import TextProcessor
            
            if not corpus_path:
                # Trouver le dernier corpus
                import glob
                corpus_files = glob.glob("corpus/corpus_*.json")
                if corpus_files:
                    corpus_path = max(corpus_files)
                else:
                    logger.error("Aucun fichier corpus trouv√©")
                    return False
            
            processor = TextProcessor(use_spacy=False)  # NLTK plus rapide
            output_path = processor.process_corpus(corpus_path)
            
            logger.info(f"Corpus pr√©trait√©: {output_path}")
            return True
        
        except Exception as e:
            logger.error(f"Erreur lors du pr√©traitement: {e}")
            return False
    
    def _run_lexical_analysis(self, corpus_path=None):
        """Ex√©cute l'analyse lexicale"""
        
        try:
            from analysis.lexical_analyzer import LexicalAnalyzer
            
            if not corpus_path:
                # Trouver le dernier corpus pr√©trait√©
                import glob
                preprocessed_files = glob.glob("preprocessed/preprocessed_*.json")
                if preprocessed_files:
                    corpus_path = max(preprocessed_files)
                else:
                    logger.error("Aucun corpus pr√©trait√© trouv√©")
                    return False
            
            analyzer = LexicalAnalyzer()
            analyzer.load_corpus(corpus_path)
            results = analyzer.analyze_all()
            
            self.results['lexical'] = results
            logger.info("Analyse lexicale compl√©t√©e")
            return True
        
        except Exception as e:
            logger.error(f"Erreur lors de l'analyse lexicale: {e}")
            return False
    
    def _run_semantic_analysis(self, corpus_path=None):
        """Ex√©cute l'analyse s√©mantique"""
        
        try:
            from analysis.semantic_analyzer import SemanticAnalyzer
            
            if not corpus_path:
                # Trouver le dernier corpus pr√©trait√©
                import glob
                preprocessed_files = glob.glob("preprocessed/preprocessed_*.json")
                if preprocessed_files:
                    corpus_path = max(preprocessed_files)
                else:
                    logger.error("Aucun corpus pr√©trait√© trouv√©")
                    return False
            
            analyzer = SemanticAnalyzer()
            analyzer.load_corpus(corpus_path)
            results = analyzer.analyze_all()
            
            self.results['semantic'] = results
            logger.info("Analyse s√©mantique compl√©t√©e")
            return True
        
        except Exception as e:
            logger.error(f"Erreur lors de l'analyse s√©mantique: {e}")
            return False
    
    def _run_sentiment_analysis(self, corpus_path=None):
        """Ex√©cute l'analyse de sentiment"""
        
        try:
            from analysis.sentiment_analyzer import SentimentAnalyzer
            
            if not corpus_path:
                # Trouver le dernier corpus pr√©trait√©
                import glob
                preprocessed_files = glob.glob("preprocessed/preprocessed_*.json")
                if preprocessed_files:
                    corpus_path = max(preprocessed_files)
                else:
                    logger.error("Aucun corpus pr√©trait√© trouv√©")
                    return False
            
            analyzer = SentimentAnalyzer()
            analyzer.load_corpus(corpus_path)
            results = analyzer.analyze_all()
            
            self.results['sentiment'] = results
            logger.info("Analyse de sentiment compl√©t√©e")
            return True
        
        except Exception as e:
            logger.error(f"Erreur lors de l'analyse de sentiment: {e}")
            return False
    
    def _generate_visualizations(self):
        """G√©n√®re les visualisations"""
        
        try:
            from visualization.visualizer import Visualizer
            
            visualizer = Visualizer()
            visualizer.load_results("analysis_results")
            visualizer.generate_all_visualizations("visualizations")
            
            logger.info("Visualisations g√©n√©r√©es")
            return True
        
        except Exception as e:
            logger.error(f"Erreur lors de la g√©n√©ration des visualisations: {e}")
            return False
    
    def _generate_report(self):
        """G√©n√®re le rapport final"""
        
        try:
            from reports.report_generator import ReportGenerator
            
            generator = ReportGenerator()
            
            # G√©n√©rer le rapport HTML
            html_path = generator.generate_html_report()
            
            # G√©n√©rer le rapport PDF
            pdf_path = generator.generate_pdf_report()
            
            logger.info(f"Rapports g√©n√©r√©s: HTML={html_path}, PDF={pdf_path}")
            return True
        
        except Exception as e:
            logger.error(f"Erreur lors de la g√©n√©ration du rapport: {e}")
            return False
    
    def _run_web_interface(self):
        """Lance l'interface web"""
        
        try:
            from web_interface.app import app
            
            # Configuration
            app.run(
                host="127.0.0.1",
                port=5000,
                debug=False,
                use_reloader=False
            )
            
            return True
        
        except Exception as e:
            logger.error(f"Erreur lors du lancement de l'interface web: {e}")
            return False
    
    def run_full_pipeline(self):
        """Ex√©cute le pipeline complet"""
        
        logger.info("="*60)
        logger.info("D√âMARRAGE DU PIPELINE COMPLET")
        logger.info("="*60)
        
        steps = [
            ("generate_sample_corpus", {}),
            ("preprocess", {}),
            ("lexical_analysis", {}),
            ("semantic_analysis", {}),
            ("sentiment_analysis", {}),
            ("visualize", {}),
            ("generate_report", {})
        ]
        
        results = {}
        
        for step_name, kwargs in steps:
            logger.info(f"\n{'-'*60}")
            logger.info(f"√âTAPE: {step_name.upper()}")
            logger.info(f"{'-'*60}")
            
            success = self.run_step(step_name, **kwargs)
            results[step_name] = success
            
            if not success:
                logger.error(f"√âtape {step_name} √©chou√©e!")
                break
            else:
                logger.info(f"√âtape {step_name} r√©ussie!")
        
        # R√©sum√©
        logger.info("\n" + "="*60)
        logger.info("R√âSUM√â DU PIPELINE")
        logger.info("="*60)
        
        for step_name, success in results.items():
            status = "‚úì" if success else "‚úó"
            logger.info(f"{status} {step_name}")
        
        successful_steps = sum(results.values())
        total_steps = len(results)
        
        logger.info(f"\n√âtapes r√©ussies: {successful_steps}/{total_steps}")
        
        if successful_steps == total_steps:
            logger.info("\nüéâ PIPELINE TERMIN√â AVEC SUCC√àS!")
            logger.info("\nProchaines √©tapes:")
            logger.info("1. Lancez l'interface web: python main.py --web")
            logger.info("2. Ouvrez votre navigateur: http://127.0.0.1:5000")
            logger.info("3. Explorez les r√©sultats!")
        else:
            logger.warning(f"\n‚ö†Ô∏è  PIPELINE TERMIN√â AVEC {total_steps - successful_steps} √âCHEC(S)")
        
        return results


def main():
    """Fonction principale"""
    
    parser = argparse.ArgumentParser(
        description="NLP Bias Analyzer - D√©tection des doubles standards dans la couverture m√©diatique"
    )
    
    parser.add_argument(
        "--step",
        choices=[
            "generate_sample_corpus",
            "preprocess",
            "lexical_analysis",
            "semantic_analysis",
            "sentiment_analysis",
            "visualize",
            "generate_report",
            "run_web_interface"
        ],
        help="Ex√©cuter une √©tape sp√©cifique du pipeline"
    )
    
    parser.add_argument(
        "--full",
        action="store_true",
        help="Ex√©cuter le pipeline complet"
    )
    
    parser.add_argument(
        "--web",
        action="store_true",
        help="Lancer uniquement l'interface web"
    )
    
    parser.add_argument(
        "--config",
        default="config/config.yaml",
        help="Chemin vers le fichier de configuration"
    )
    
    args = parser.parse_args()
    
    # Initialiser l'orchestrateur
    orchestrator = PipelineOrchestrator(config_path=args.config)
    
    # Ex√©cuter l'action demand√©e
    if args.full:
        # Pipeline complet
        orchestrator.run_full_pipeline()
    
    elif args.web:
        # Interface web seulement
        logger.info("Lancement de l'interface web...")
        orchestrator.run_step("run_web_interface")
    
    elif args.step:
        # √âtape sp√©cifique
        logger.info(f"Ex√©cution de l'√©tape: {args.step}")
        success = orchestrator.run_step(args.step)
        
        if success:
            logger.info(f"‚úì √âtape {args.step} r√©ussie!")
        else:
            logger.error(f"‚úó √âtape {args.step} √©chou√©e!")
            sys.exit(1)
    
    else:
        # Afficher l'aide
        parser.print_help()
        print("\nExemples d'utilisation:")
        print("  python main.py --full                    # Pipeline complet")
        print("  python main.py --web                     # Interface web seulement")
        print("  python main.py --step preprocess         # Pr√©traitement seulement")
        print("  python main.py --step lexical_analysis   # Analyse lexicale")


if __name__ == "__main__":
    main()